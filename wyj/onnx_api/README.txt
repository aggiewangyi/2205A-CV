The api is prepared for using onnx-inference without any change.
You can use is by enter the picture, and get the result.
If you wanna use your own onnx file don't forget to change the "onnx_model"
